# -*- coding: utf-8 -*-
"""H_flip

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11STe5EZP1-EPtjssP_szc6okFk8hF2q9
"""

import torch
import torchvision.transforms as transforms
from torchvision import datasets

# Assuming 'datas' is a DataLoader containing your images

# Define a transform to horizontally flip the images
transform = transforms.Compose([transforms.RandomHorizontalFlip(p=1)])

# Create a list to store the flipped images
flipped_images = []

# Loop through the DataLoader and apply the transformation to each image
for batch in datas:
    batch_flipped = torch.stack([transform(image) for image in batch])
    flipped_images.append(batch_flipped)

# Convert the list of flipped images to a tensor
flipped_images_tensor = torch.cat(flipped_images, dim=0)

# Print the shape of the flipped images tensor
print("Flipped images tensor shape:", flipped_images_tensor.shape)

import torch
import torchvision.transforms as transforms
from torchvision import datasets

# Assuming 'datas' is a DataLoader containing your images

# Define a transform to horizontally flip the images
transform = transforms.Compose([transforms.RandomHorizontalFlip(p=1)])

# Apply the transform to each batch of images using list comprehensions
flipped_images = [torch.stack([transform(image) for image in batch]) for batch in datas]

# Concatenate the list of flipped image batches along the batch dimension
flipped_images_tensor = torch.cat(flipped_images, dim=0)

# Print the shape of the flipped images tensor
print("Flipped images tensor shape:", flipped_images_tensor.shape)